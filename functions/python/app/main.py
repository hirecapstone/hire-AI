import os
import time
import warnings
import re
import json
import glob
import subprocess

import openai
from openai import OpenAI
from firebase_admin import credentials, firestore, initialize_app, storage
from flask import Flask, request, jsonify
from google.api_core.exceptions import AlreadyExists

# â€”â€”â€”â€”â€” ì„¤ì • â€”â€”â€”â€”â€”
MAX_BYTES = 25 * 1024 * 1024  # Whisper API ìµœëŒ€ íŒŒì¼ í¬ê¸° (25MB)
SEGMENT_SECONDS = 300
# ë§ ë¹ ë¥´ê¸° ë¶„ë¥˜ ê¸°ì¤€ (WPM)
SLOW_WPM = 80.0
FAST_WPM = 120.0
warnings.filterwarnings("ignore")

# OpenAI í‚¤ (í™˜ê²½ë³€ìˆ˜ì— ë¯¸ë¦¬ ì„¤ì •í•´ì£¼ì„¸ìš”)
openai.api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=openai.api_key)

# Firebase ì´ˆê¸°í™”
cred_path = os.path.join(
    os.path.dirname(__file__),
    "firebase/hire-ai-a11ed-firebase-adminsdk-fbsvc-0b544a898e.json"
)
initialize_app(
    credentials.Certificate(cred_path),
    {'storageBucket': 'hire-ai-a11ed.firebasestorage.app'}
)

db     = firestore.client()
bucket = storage.bucket()
app    = Flask(__name__)

def classify_speed(wpm: float, slow_wpm: float = SLOW_WPM, fast_wpm: float = FAST_WPM) -> str:
    """
    WPM ê¸°ì¤€ìœ¼ë¡œ ë§ ë¹ ë¥´ê¸° ë¼ë²¨ë§:
      wpm == 0                 â†’ 'no_speech'  (ë°œí™” ì—†ìŒ)
      wpm < slow_wpm           â†’ 'slow'
      slow_wpm <= wpm <= fast_wpm â†’ 'normal'
      wpm > fast_wpm           â†’ 'fast'
    """
    if wpm == 0:
        return "no_speech"
    if wpm < slow_wpm:
        return "slow"
    elif wpm > fast_wpm:
        return "fast"
    else:
        return "normal"
    
def _split_audio(path: str) -> list[str]:
    """
    FFmpegë¥¼ ì‚¬ìš©í•´ WAV íŒŒì¼ì„ ì—¬ëŸ¬ ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    """
    base = os.path.splitext(path)[0]
    pattern = f"{base}_seg%03d.wav"
    subprocess.run([
        'ffmpeg', '-y', '-i', path,
        '-ar', '16000', '-ac', '1',
        '-f', 'segment', '-segment_time', str(SEGMENT_SECONDS), pattern
    ], check=True)
    return sorted(glob.glob(f"{base}_seg*.wav"))


def transcribe_video(path: str,silence_thresh: float = 0.6) -> tuple[str, float]:
    """
    Whisper API ì „ì‚¬ìš©. íŒŒì¼ì´ 25MBë¥¼ ë„˜ìœ¼ë©´ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜ í›„ ë¶„í• í•˜ì—¬ ì „ì‚¬.
    """
    parts = [path]
    if os.path.getsize(path) > MAX_BYTES:
        wav_path = path.replace('.mp4', '.wav')
        subprocess.run(['ffmpeg', '-y', '-i', path, wav_path], check=True)
        parts = _split_audio(wav_path)

    all_texts      = []
    total_duration = 0.0  # seconds
    total_words    = 0

    for part in parts:
        with open(part, 'rb') as f:
            resp = client.audio.transcriptions.create(
                file=f,
                model='whisper-1',
                response_format='verbose_json', 
                temperature=0,                   
                language='ko'
            )
        segments = [
            seg for seg in resp.segments
            if getattr(seg, "no_speech_prob", 1.0) < silence_thresh
        ]
        # ì „ì‚¬ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
        text = "".join(seg.text for seg in segments)
        all_texts.append(text)
        # ì¬ìƒ ì‹œê°„ ë° ë‹¨ì–´ìˆ˜ í•©ì‚°
        total_duration += sum((seg.end - seg.start) for seg in segments)
        total_words    += sum(len(seg.text.split()) for seg in segments)
    transcription = ' '.join(all_texts)
    wpm = (total_words / total_duration * 60) if total_duration > 0 else 0.0
    return transcription, wpm


def process_videos(session_id: str):
    """
    1) videos/{session_id}/*.mp4 9ê°œ â†’ Whisperë¡œ ìë§‰ ë½‘ì•„ interview_answersì— ì €ì¥
    2) interview_questionsì—ì„œ ì§ˆë¬¸ 9ê°œ ì½ì–´ì™€ ChatGPT í”¼ë“œë°±+ì ìˆ˜ â†’ interview_feedbackì— ì €ì¥
    ê° ë‹¨ê³„ë³„ ì†Œìš”ì‹œê°„ ë¡œê·¸ ì¶œë ¥.
    """
    t0_total = time.time()
    print(f"[{session_id}] â–¶ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘", flush=True)

    # 1) Whisper ì²˜ë¦¬ & interview_answers ì €ì¥
    t0_wh = time.time()
    prefix = f"videos/{session_id}/"
    blobs  = list(bucket.list_blobs(prefix=prefix))
    videos = sorted([b for b in blobs if b.name.lower().endswith(".mp4")], key=lambda b: b.name)

    transcripts = []
    speed_labels = []

    for idx, blob in enumerate(videos, start=1):
        name      = os.path.basename(blob.name)
        local_mp4 = f"/tmp/{name}"

        dl0 = time.time()
        blob.download_to_filename(local_mp4)
        print(f"[{session_id}] ({idx}/{len(videos)}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (â± {time.time()-dl0:.1f}s)", flush=True)

        wh0 = time.time()
        try:
            text, wpm = transcribe_video(local_mp4)
            speed = classify_speed(wpm)
        except Exception as e:
            print(f"[{session_id}] ({idx}) ì „ì‚¬ ì‹¤íŒ¨: {e}", flush=True)
            text = ""
            speed = "no_speech"
            wpm    = 0.0
        transcripts.append(text)
        speed_labels.append(speed)
        print(f"[{session_id}] ({idx}/{len(videos)}) Whisper ë¶„ì„ ì™„ë£Œ (â± {time.time()-wh0:.1f}s)", flush=True)
    print(f"[{session_id}] ğŸ“ Whisper ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {time.time()-t0_wh:.1f}s", flush=True)

    db.collection('interview_answers').document(session_id).set({
        'text': transcripts
    })
    print(f"[{session_id}] âœ… interview_answers ì €ì¥ ì™„ë£Œ", flush=True)

    # 2) ChatGPT í”¼ë“œë°±+ì ìˆ˜ ìƒì„± & interview_feedback ì €ì¥
    t0_q = time.time()
    q_doc = db.collection('interview_questions').document(session_id).get()
    if q_doc.exists:
        q_data = q_doc.to_dict()
        questions = [] + q_data.get('questions', [])
    else:
        questions = []
    print(f"[{session_id}] â„¹ï¸ ì§ˆë¬¸ ë¡œë”© ì™„ë£Œ (â± {time.time()-t0_q:.1f}s)", flush=True)

    feedbacks = []
    total_scores = []
    scores_details = []
    t0_fb = time.time()

    for idx, (q, a) in enumerate(zip(questions, transcripts), start=1):
        fb0 = time.time()
        prompt = (
            f"ì§ˆë¬¸: {q}\n"
            f"ë‹µë³€: {a}\n\n"
            "ì•„ë˜ í˜•ì‹(JSON)ìœ¼ë¡œë§Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”:\n"
            "1) feedback: í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•œ í”¼ë“œë°± ì‘ì„±\n"
            "2) scores: ë‹¤ì„¯ ê°€ì§€ ê¸°ì¤€(Relevance, Completeness, Clarity, Logic, Length)ì— ëŒ€í•´ **0,1,2,3,4,5**ì˜ ì •ìˆ˜ë§Œ ì‚¬ìš©í•˜ì—¬ ì±„ì  (true/false ì‚¬ìš© ê¸ˆì§€)\n"
            "   **0.0ì—ì„œ 5.0 ì‚¬ì´ ì‹¤ìˆ˜**ë¡œ ì±„ì  (ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€)\n"
            "   - ì˜ˆ: 0.0, 1.5, 3.2, 4.0, 5.0\n"
            "3) total: scores ê°’ë“¤ì˜ í‰ê· ì„ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼\n\n"
            # ì˜ˆì‹œ JSON
            '{"feedback":"ë‹µë³€ì´ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ìœ¼ë‚˜, êµ¬ì²´ì ì¸ ì˜ˆì‹œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",'
            '"scores":{"relevance":4.2,"completeness":3.5,"clarity":4.8,"logic":4.0,"length":2.7},'
            '"total":3.44}'
        )
        
        resp = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role":"system", "content":"ë„ˆëŠ” ê³µì •í•œ ë©´ì ‘ê´€ì…ë‹ˆë‹¤."},
                {"role":"user",   "content": prompt}
            ],
            temperature=0,
            max_tokens=256
        )
        
        raw = resp.choices[0].message.content
        print(f"[DEBUG][{session_id}] Raw GPT response (1st):\n{raw}", flush=True)
        data = json.loads(raw)

        feedbacks.append(data.get("feedback", ""))
        total_scores.append(float(data.get("total", 0.0)))

        detail = data.get("scores", {})
        detail = {k: round(float(v), 1) for k, v in data["scores"].items()}
        scores_details.append(detail)

        print(f"[{session_id}] ({idx}/{len(questions)}) í”¼ë“œë°±+ì ìˆ˜ ìƒì„± ì™„ë£Œ (â± {time.time()-fb0:.1f}s)", flush=True)

    print(f"[{session_id}] ğŸ’¬ í”¼ë“œë°±+ì ìˆ˜ ì „ì²´ ìƒì„± ì‹œê°„: {time.time()-t0_fb:.1f}s", flush=True)

    # í‰ê·  ê³„ì‚°
    avg_total = round(sum(total_scores) / len(total_scores), 2) if total_scores else 0
    avg_per_criterion = {}
    if scores_details:
        for key in scores_details[0].keys():
            avg_per_criterion[key] = round(
                sum(d[key] for d in scores_details) / len(scores_details), 2
            )

    # Firestoreì— í”¼ë“œë°±ê³¼ ì ìˆ˜ ì €ì¥
    db.collection('interview_feedback').document(session_id).set({
        'feedbacks': feedbacks,
        'total_scores': total_scores,
        'scores_details': scores_details,
        'avg_total_score': avg_total,
        'avg_scores_per_criterion': avg_per_criterion,
        'speed': speed_labels
    })
    print(f"[{session_id}] âœ… interview_feedback ì €ì¥ ì™„ë£Œ (í‰ê· ì´ì ={avg_total}, ê¸°ì¤€ë³„í‰ê· ={avg_per_criterion})", flush=True)

    print(f"[{session_id}] ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì´ ì†Œìš”ì‹œê°„: {time.time()-t0_total:.1f}s", flush=True)

@app.route('/', methods=['POST'])
def handle_event():
    # Cloud Storage finalized ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬
    ce = request.headers.get('ce-type') or request.headers.get('Ce-Type')
    if ce != 'google.cloud.storage.object.v1.finalized':
        return jsonify({"status":"ignored"}), 200

    payload = request.get_json(silent=True) or {}
    data    = payload.get('data', payload)
    gen     = data.get('metageneration')
    name    = data.get('name')

    # ì²«ë²ˆì§¸ ë©”íƒ€ì  ì´ ì•„ë‹ˆê±°ë‚˜ ì´ë¦„ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
    if str(gen) != "1" or not name:
        return jsonify({"status":"ignored"}), 200

    # videos/{session_id}/{session_id}_qN.mp4 íŒ¨í„´ë§Œ
    if not re.fullmatch(r"videos/[^/]+/[^/]+_q\d+\.mp4", name):
        return jsonify({"status":"ignored"}), 200

    session_id = name.split('/', 2)[1]

    # Firestoreì—ì„œ ì§ˆë¬¸ ê°œìˆ˜ ì¡°íšŒ
    q_doc = db.collection('interview_questions').document(session_id).get()
    questions = q_doc.to_dict().get("questions", []) if q_doc.exists else []
    expected_videos = len(questions)

    # ì—…ë¡œë“œëœ ë™ì˜ìƒ ê°œìˆ˜ í™•ì¸
    prefix = f"videos/{session_id}/"
    blobs  = [b for b in bucket.list_blobs(prefix=prefix)
              if b.name.lower().endswith(".mp4")]
    if len(blobs) < expected_videos:
        print(f"[{session_id}] ì•„ì§ ì—…ë¡œë“œ {len(blobs)}/{expected_videos}ê°œ â†’ waiting", flush=True)
        return jsonify({"status":"waiting"}), 200

    # 7. ìµœì´ˆ ì§„ì… ì‹œ ë½ ìƒì„± ì‹œë„ (í•œ ë²ˆë§Œ ì„±ê³µ)
    lock_ref = db.collection('batch_locks').document(session_id)
    try:
        lock_ref.create({'done': True})
    except AlreadyExists:
        print(f"[{session_id}] ì´ë¯¸ ë°°ì¹˜ ì²˜ë¦¬ë¨ â†’ skip", flush=True)
        return jsonify({"status":"skipped"}), 200

    # 8. ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
    try:
        process_videos(session_id)
    except Exception as e:
        print(f"[{session_id}] ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", flush=True)
        # í•„ìš”í•˜ë‹¤ë©´ ë½ì„ ì§€ìš°ê³  ì¬ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
        # lock_ref.delete()
        return jsonify({"status":"error", "reason": str(e)}), 500



    return jsonify({"status":"done"}), 200
if __name__ == "__main__":
    app.run(host='0.0.0.0', port=8080)
